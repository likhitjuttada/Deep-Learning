{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c2351ee",
   "metadata": {},
   "source": [
    "## _CSE 574 - Assignment 2 (Decision Trees)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a5d82d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c173ec5b",
   "metadata": {},
   "source": [
    "### data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05a05f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bb907ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "# print the desctiption of the dataset given by sklearn \n",
    "description = data['DESCR']\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4dc6e9",
   "metadata": {},
   "source": [
    "### data-preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ded0d7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restructure the data to form a dataframe for data pre-processing\n",
    "features = data['data']\n",
    "target = data['target'].reshape(-1,1)\n",
    "\n",
    "feature_names = data['feature_names']\n",
    "target_names = data['target_names']\n",
    "\n",
    "dataset = np.hstack((features, target))\n",
    "\n",
    "# convert data into dataframe\n",
    "df = pd.DataFrame(dataset, columns = feature_names + [\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebc06ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   class  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    0.0  \n",
       "4    0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cf79ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sepal length (cm)  150 non-null    float64\n",
      " 1   sepal width (cm)   150 non-null    float64\n",
      " 2   petal length (cm)  150 non-null    float64\n",
      " 3   petal width (cm)   150 non-null    float64\n",
      " 4   class              150 non-null    float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 6.0 KB\n"
     ]
    }
   ],
   "source": [
    "# There seem to be no null values in the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed882a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.057333           3.758000   \n",
       "std             0.828066          0.435866           1.765298   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)       class  \n",
       "count        150.000000  150.000000  \n",
       "mean           1.199333    1.000000  \n",
       "std            0.762238    0.819232  \n",
       "min            0.100000    0.000000  \n",
       "25%            0.300000    0.000000  \n",
       "50%            1.300000    1.000000  \n",
       "75%            1.800000    2.000000  \n",
       "max            2.500000    2.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe the statistics of individual columns in the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aaca75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2.]\n"
     ]
    }
   ],
   "source": [
    "# print unique values of the target variable, it is descrete as needed for classification\n",
    "print(df[\"class\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4478213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data has no null values and has an equal distribution of each class in the dataset.\n",
    "# Hence pre-processing of data is not practically needed, we can proceed with test-train split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825c71d7",
   "metadata": {},
   "source": [
    "### test-train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45a58c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['data']\n",
    "y = data['target']\n",
    "\n",
    "# assign 75% of the data as train, and utilize the rest for test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7a71d6",
   "metadata": {},
   "source": [
    "### decision-tree implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cce32148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "\n",
    "    \"\"\" The function calculates the entropy based on the formula: -(p_*log(p_) + p*log(p))\n",
    "            here, p_ = the probability of occurrance of one type of class\n",
    "                  p = the probability of occurrance of another class type\n",
    "        \"\"\"\n",
    "\n",
    "    # return the count of every unique value in the target label\n",
    "    _, count = np.unique(y, return_counts=True)\n",
    "    probabilities = count / len(y)\n",
    "\n",
    "    return -np.sum([p * np.log2(p) for p in probabilities])\n",
    "\n",
    "def gain(X, y, feature_index, split_point):\n",
    "\n",
    "    \"\"\" The function returns the information gain based on a split_point for a given feature \n",
    "        Formula for information gain, IG = E(Y) - E(Y|X)\n",
    "    \"\"\"\n",
    "\n",
    "    # perform binary split based on the split point of the feature\n",
    "    left_split = X[:, feature_index] <= split_point\n",
    "    right_split = X[:, feature_index] > split_point\n",
    "\n",
    "    # calculate entropy of each split\n",
    "    left_entropy = entropy(y[left_split])\n",
    "    right_entropy = entropy(y[right_split])\n",
    "\n",
    "    # get the weights of split \n",
    "    left_weight = np.sum(left_split)/ len(y)\n",
    "    right_weight = np.sum(right_split)/ len(y)\n",
    "\n",
    "    # calculate weighted entropy\n",
    "    weighted_entropy = (left_weight * left_entropy) + (right_weight * right_entropy)\n",
    "\n",
    "    # return information gain for a specific feature\n",
    "    return entropy(y) - weighted_entropy\n",
    "\n",
    "def best_split(X, y):\n",
    "\n",
    "    \"\"\" The function loops over all the unique values in each feature and selects the best feature and split point combination \n",
    "        that gives the maximum information gain\n",
    "    \"\"\"\n",
    "    best_feature_index = 0\n",
    "    best_split_point = 0\n",
    "    best_gain = -100000\n",
    "\n",
    "    for index in range(X.shape[1]):\n",
    "        \n",
    "        # calculate gain for each feature\n",
    "        unique_values = np.unique(X[:, index])\n",
    "        for value in unique_values:\n",
    "            \n",
    "            # compare previous gains\n",
    "            g = gain(X, y, index, value)\n",
    "            if g > best_gain:\n",
    "                best_gain = g\n",
    "                best_feature_index = index\n",
    "                best_split_point = value\n",
    "\n",
    "    return best_feature_index, best_split_point\n",
    "\n",
    "def build_train(X, y, depth=0, max_depth = 3):\n",
    "    \n",
    "    \"\"\" The function builds a recursive binary decision tree with a maximum allowed depth\n",
    "        Recursive calls are used to pass the last split data set and build the left and right sub-trees\n",
    "    \"\"\"\n",
    "    # check for the edge case; current_depth > maximum_depth\n",
    "    if depth >= max_depth:\n",
    "        return np.bincount(y).argmax()\n",
    "\n",
    "    # check for edge case; the node has only one type of observations\n",
    "    if len(np.unique(y)) == 1:\n",
    "        return y[0]\n",
    "\n",
    "    # obtain the best split\n",
    "    best_feature_index, best_split_point = best_split(X, y)\n",
    "\n",
    "    left_filter = X[:, best_feature_index] <= best_split_point\n",
    "    right_filter = X[:, best_feature_index] > best_split_point\n",
    "    \n",
    "    # recursive calls to build the decision tree\n",
    "    left_subtree = build_train(X[left_filter], y[left_filter], depth + 1, max_depth)\n",
    "    right_subtree = build_train(X[right_filter], y[right_filter], depth + 1, max_depth)\n",
    "    \n",
    "    return (best_feature_index, best_split_point, left_subtree, right_subtree)\n",
    "\n",
    "def predict_instance(instance, tree):\n",
    "    \n",
    "    \"\"\" The function sends individual feature vectors to the model and returns the prediction of the model as an integer\n",
    "        between 0-2\n",
    "    \"\"\"\n",
    "        \n",
    "    # edge case; it denotes that we are at the leaf node\n",
    "    if type(tree) == np.int32 or type(tree) == np.int64:\n",
    "        return tree\n",
    "    else:\n",
    "        feature_index, split_value, left_subtree, right_subtree = tree\n",
    "\n",
    "        # recursively traverse the tree to check where the corresponding observation falls\n",
    "        if instance[feature_index] <= split_value:\n",
    "            return predict_instance(instance, left_subtree)\n",
    "        else:\n",
    "            return predict_instance(instance, right_subtree)\n",
    "\n",
    "def predict(X, tree):\n",
    "        \n",
    "        \"\"\" The function takes the training set as input and returns the predictions made by the model as an output numoy array\n",
    "            It calls the predict_instance method on each feature vector of the test set\n",
    "        \"\"\"\n",
    "        \n",
    "        result = list()\n",
    "        # loop over the test set and gather predictions\n",
    "        for instance in X:\n",
    "            result.append(predict_instance(instance, tree))\n",
    "        \n",
    "        return np.array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7661ca",
   "metadata": {},
   "source": [
    "### model training & evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2558dd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is: 0.95\n"
     ]
    }
   ],
   "source": [
    "# build and train the decision tree\n",
    "tree = build_train(X_train, y_train)\n",
    "\n",
    "# make predictions using test set\n",
    "y_pred = predict(X_test, tree)\n",
    "\n",
    "# evaluate accuracy of the model\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(\"Accuracy of the model is:\", accuracy.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9a164d",
   "metadata": {},
   "source": [
    "### analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59077f5b",
   "metadata": {},
   "source": [
    "### Since the dataset is small, the model is able to perform well and achieves a high accuracy for a tree depth of 3. However, the tree can easily overfit and perform poorly if we slightly increase the depth. \n",
    "\n",
    "### Performing only binary splits could potentially limit the performance of decision trees in certain cases. Furthermore the greedy approach followed for splitting might not be the best approach as certain splits might harm the performance than benefit the model.\n",
    "\n",
    "### However the decision tree formed here is easily interpreted and is non-parametric in nature. So we can be confident about the predictions of our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
