{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TfHJfVOeWsx8"
      },
      "outputs": [],
      "source": [
        "# necessary imports\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define a neural network for Image Classification\n",
        "def get_mnist_model():\n",
        "    inputs = keras.Input(shape=(28 * 28,))\n",
        "    features = keras.layers.Dense(512, activation=\"relu\")(inputs)\n",
        "    outputs = keras.layers.Dense(10, activation=\"softmax\")(features)\n",
        "\n",
        "    return keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "jG6aDMwLXq7u"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load and pre-process images\n",
        "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
        "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
        "train_images, val_images = images[10000:], images[:10000]\n",
        "train_labels, val_labels = labels[10000:], labels[:10000]"
      ],
      "metadata": {
        "id": "eBAmXz8nlHr9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15f94223-2bd9-4922-da4e-b098f29d4180"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IY_s9Sb9qDC-",
        "outputId": "b0374d2a-3623-471b-de1b-4dd199c6f59a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 8, 7, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics are instruments that can measure the performance of a model during training and validation and are more interpretable than loss fucntions.\n",
        "\n",
        "Unlike model weights they are not updated by the model using back-propagation.\n",
        "\n",
        "Keras allows the users to define custom metrics"
      ],
      "metadata": {
        "id": "m3vNyQdllmXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RootMeanSquaredError(keras.metrics.Metric):\n",
        "    def __init__(self, name=\"rmse\", **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
        "        self.total_samples = self.add_weight(name=\"total_samples\", initializer=\"zeros\", dtype = tf.int32)\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "\n",
        "        y_true = tf.one_hot(y_true, tf.shape(y_pred)[1])\n",
        "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
        "        self.mse_sum.assign_add(mse)\n",
        "        self.total_samples.assign_add(tf.shape(y_pred)[0])\n",
        "\n",
        "    def result(self):\n",
        "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.mse_sum.assign(0.)\n",
        "        self.total_samples.assign(0)"
      ],
      "metadata": {
        "id": "ztk2i1uSU1Zb"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`reset_state()`: Called at the start of each epoch to reset metrics.\n",
        "\n",
        "`result()`:Called at the end of the epoch to compute and return the final metric value based on the accumulated state.\n",
        "\n",
        "`update_state()`: Called for each batch to update the state with new predictions.\n",
        "\n"
      ],
      "metadata": {
        "id": "tqcwpH6Dc46A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_mnist_model()\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=25,\n",
        "          validation_data = (val_images, val_labels),\n",
        "          # earlystopping monitors rmse metric and stops training the model when it stops minimizing for more than 3 epochs\n",
        "          # model checkpoint saves a model at the end of every epoch. It only overrides a saved model if the validation loss improves\n",
        "          callbacks = [ keras.callbacks.EarlyStopping(monitor = \"rmse\", patience = 3, verbose = 1),\n",
        "                        keras.callbacks.ModelCheckpoint(filepath = \"mymodel.h5\", verbose = 1, monitor = \"val_loss\", save_best_only= True)]\n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n0g83nVX2tJ",
        "outputId": "49abed29-1077-4a40-f8ae-226eae0ce93e"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1559/1563 [============================>.] - ETA: 0s - loss: 0.2207 - accuracy: 0.9342 - rmse: 7.2314\n",
            "Epoch 1: val_loss improved from inf to 0.13382, saving model to mymodel.h5\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2205 - accuracy: 0.9342 - rmse: 7.2310 - val_loss: 0.1338 - val_accuracy: 0.9622 - val_rmse: 7.3643\n",
            "Epoch 2/25\n",
            "  35/1563 [..............................] - ETA: 7s - loss: 0.1007 - accuracy: 0.9714 - rmse: 7.3784"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1555/1563 [============================>.] - ETA: 0s - loss: 0.0945 - accuracy: 0.9721 - rmse: 7.3858\n",
            "Epoch 2: val_loss improved from 0.13382 to 0.09437, saving model to mymodel.h5\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0943 - accuracy: 0.9721 - rmse: 7.3853 - val_loss: 0.0944 - val_accuracy: 0.9736 - val_rmse: 7.4103\n",
            "Epoch 3/25\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.0643 - accuracy: 0.9804 - rmse: 7.4172\n",
            "Epoch 3: val_loss improved from 0.09437 to 0.09247, saving model to mymodel.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0643 - accuracy: 0.9804 - rmse: 7.4167 - val_loss: 0.0925 - val_accuracy: 0.9729 - val_rmse: 7.4205\n",
            "Epoch 4/25\n",
            "1558/1563 [============================>.] - ETA: 0s - loss: 0.0473 - accuracy: 0.9856 - rmse: 7.4330\n",
            "Epoch 4: val_loss improved from 0.09247 to 0.08646, saving model to mymodel.h5\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0473 - accuracy: 0.9855 - rmse: 7.4324 - val_loss: 0.0865 - val_accuracy: 0.9780 - val_rmse: 7.4365\n",
            "Epoch 4: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x786d627e81c0>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "While coding the custom metric class, I realized a key distinction between `y_pred.shape[0]` and `tf.shape(y_pred)[0]`, as they often appear to yield the same result. However, there's a subtle yet crucial distinction, especially in the context of TensorFlow and dynamic computation graphs.\n",
        "\n",
        "**Static vs. Dynamic Shapes**\n",
        "\n",
        "- **`y_pred.shape[0]`:** This attempts to access the shape of `y_pred` as a static attribute. In simple scenarios, where the shape is known and fixed beforehand, this works fine. It directly returns the size of the first dimension (typically the batch size).\n",
        "- **`tf.shape(y_pred)[0]`:** This uses TensorFlow's `tf.shape` function. This function is designed to work within TensorFlow's computation graph and can handle both static and *dynamic* shapes. A dynamic shape means the size of a tensor (like your batch size) might not be known until runtime."
      ],
      "metadata": {
        "id": "Kffz99YcdXco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_set_performance = model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "id": "9uD1X7t7lSGE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0af4989f-090c-4df9-eaf8-21f51ab6b746"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0812 - accuracy: 0.9791 - rmse: 7.4495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reference from the textbook: Deep learning with Python by Francois Chollet"
      ],
      "metadata": {
        "id": "gBdLzP-ZlXBY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}